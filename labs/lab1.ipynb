{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Loading and plotting geophysical data\n",
    "\n",
    "In this lab, we'll use some common Python tools to load and plot some geophysical datasets seen in [Lecture 1](https://www.leouieda.com/envs398/slides/1-plate-tectonics/). We will write the code together and there are some questions for you to answer regarding the datasets.\n",
    "\n",
    "We'll cover 3 data types routinely used in scientific Python:\n",
    "\n",
    "* `pandas.DataFrame`: for tables\n",
    "* `numpy.array`: for arrays (matrices, vectors, etc)\n",
    "* `xarray.Dataset` and `xarray.DataArray`: for grids\n",
    "\n",
    "## General instructions\n",
    "\n",
    "This is a [Jupyter notebook](https://jupyter.org/) running in [Jupyter Lab](https://jupyterlab.readthedocs.io/en/stable/). The notebook is a programming environment that mixes code (the parts with `[1]: ` or similar next to them) and formatted text/images/equations with [Markdown](https://www.markdownguide.org/basic-syntax) (like this part right here).\n",
    "\n",
    "Quick start guide:\n",
    "\n",
    "* **Edit** any cell (blocks of code or text) by double clicking on it.\n",
    "* **Execute** a code or Markdown cell by typing `Shift + Enter` after selecting it.\n",
    "* The current active cell is the one with a **blue bar next to it**.\n",
    "* You can run cells **in any order** as long as the code sequence makes sense (it's best to go top-to-bottom, though).\n",
    "* To copy any file to the current directory, drag and drop it to the file browser on the left side.\n",
    "* Notebook files have the extension `.ipynb`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import things\n",
    "\n",
    "First thing to do is load the Python libraries that we'll be using. The power of the many available libraries is what makes Python so powerful. We'll group all our imports here at the top to make it easier to see what we're using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To open compressed files. Part of the Python standard library. \n",
    "import gzip\n",
    "import bz2\n",
    "# For making plots and figures\n",
    "import matplotlib.pyplot as plt\n",
    "# The base of the entire scientific Python stack\n",
    "import numpy as np\n",
    "# For working with tables\n",
    "import pandas as pd\n",
    "# For working with grids\n",
    "import xarray as xr\n",
    "# Nice colormaps for geoscience\n",
    "import cmocean\n",
    "# For plotting with projections\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPS velocities from the Plate Boundary Observatory\n",
    "\n",
    "We'll start with the GPS velocity data for North America. \n",
    "\n",
    "2. In the Jupyter lab file browser (left) create a new folder called `data`.\n",
    "1. Download the data file `pbo.final_igs14.vel` from the UNAVCO ftp site: ftp://data-out.unavco.org/pub/products/velocity/\n",
    "2. Find the data file on your computer and drag it to the `data` folder in the file browser on the left\n",
    "3. In the cell below, we'll load the data using `pandas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Access individual columns by \"indexing\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velocities[\"Ref_X\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use matplotib to make a plot of the station locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cartopy` to make the plot using a map projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the vectors using the `quiver` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global seismicity catalog\n",
    "\n",
    "Now we'll move on to the Global CMT catalog of earthquake hypocenters.\n",
    "\n",
    "1. Download the \"gzip compressed\" version of the catalog from https://www.globalcmt.org/CMTfiles.html\n",
    "2. Drag it to the `data` folder.\n",
    "\n",
    "This is one is trickier because there is no clear structure to the file. So tools like `pandas` and `numpy` won't be able to load it. We'll have to do this ourselves then..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the data easier to use, we can convert it to a `numpy.array`. This is the basic datatype used for most scientific Python packages ad forms the basis for the entire stack."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `cartopy` to plot the location and depth of earthquakes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age of the oceanic crust\n",
    "\n",
    "The age of the oceanic crust dataset is a grid. The typical format many people use to store grids is called [NetCDF](https://en.wikipedia.org/wiki/NetCDF) (usually with extension `.nc` or `.grd`). To handle this type of dataset, we will use the `xarray` library.\n",
    "\n",
    "1. Download the \"Crustal Age\" grid version 3 at 6 arc-minute resolution in NetCDF format (`age.3.6.nc.bz2`) from NOAA: https://www.ngdc.noaa.gov/mgg/ocean_age/ocean_age_2008.html\n",
    "2. Drag it to the `data` folder.\n",
    "3. Use `xarray.open_dataarray` to load it with `bz2` to decompress the file first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the grid using `pcolormesh` from matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do those values look correct?** Read the `readme.txt` file on the NOAA server: https://www.ngdc.noaa.gov/mgg/ocean_age/data/2008/grids/age/readme.txt (If a file is called \"readme\", always read it)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "Discuss the following in small groups:\n",
    "\n",
    "1. Does sea floor spreading happen at the same rate everywhere?\n",
    "2. Does the maximum earthquake depth indicate the maximum depth of subduction?\n",
    "3. Which aspect of loading data in Python did you find most difficult?\n",
    "4. What could be done to make it easier?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:env398]",
   "language": "python",
   "name": "conda-env-env398-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
